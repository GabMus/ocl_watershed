<!doctype html>
<html>
    <head>
        <meta charset="utf-8"/>
        <title>Watershed transform implementation for GPU architectures in OpenCL</title>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <link rel="stylesheet" href="./github-markdown.css">

		<script src="./Chart.min.js"></script>
        <script src="./marked.min.js"></script>

		<style>
			canvas {
				max-width: 1200px;
			}

            #markdownContent img {
                display: block;
                margin: auto;
            }

            #markdownContent img:active {
                position: fixed;
                max-width: 100vw;
                max-height: 100vh;
                top: 50%;
                left: 50%;
                transform: translate(-50%, -50%);
            }
		</style>
    </head>
    <body>
        <div id="markdownContent" class="markdown-body">
# Watershed transform implementation for GPU architectures in OpenCL

### Gabriele Musco (emaildigabry@gmail.com)

#### *This work is licensed under a [Creative Commons Attribution-ShareAlike 4.0 International License](./LICENSE.txt)*

---

# Description

In image processing, watershed is a segmentation algorithm that is based around the idea of treating the image like a topographic map, where the brightness of each pixel represents the height, and finds the lines that connect together the highest points.

There are some different methods of treating the watershed, one of them is by topographic distance. Using this method it is possible to treat the image like a graph, and use a cellular automaton to implement a parallel version of the Bellman-Ford's shortest paths algorithm.

# Implementation

This implementation of the watershed transform is written using C++ for the host (CPU) code and OpenCL for the device (GPU) code.

The fist step is to convert the input image (provided in the ppm format for convenience) to grayscale (this also brings the image to the linear space, as opposed to the gamma space that most - if not all - images use).

Right after that the program applies a gradient convolution matrix to the grayscale image to find the local minima in it (the positions in which the values of the gradient image are 0).

Then the program initializes two matrices of the same size as the image (lattice and labels) for the time t<sub>0</sub>. The lattice value for each pixel is 0 if it is a minimum, otherwise +&infin;; the label value for each pixel is the (linearized) pixel position if it is a minimum, otherwise 0.

Once the t<sub>0</sub> matrices are initialized, the automaton is started in a loop, computing locally the new t<sub>i+1</sub> matrices using the data from the t<sub>i</sub> ones. At the end of each loop cycle, the automaton checks if the two sets of matrices are different; if so, the loop goes on, otherwise it stops, meaning that the watershed is complete.

Finally a new image is created, where the color of each pixel in position (x, y) corresponds with the color of the pixel in the original image in the position indicated by the label in position (x, y).

## The *Cellular Automaton*

This is the core of the algorithm, as it computes the actual watershed segmentation.

The automaton works locally for each pixel, analyzing it and its 4 nearest neighbors and deciding for each step of the loop to which segment it should belong to.

There are 3 different versions of the automaton, each one being more suited for different hardware:

- A global memory implementation, without any particular optimizations (target: newer GPUs with hardare caching, devices without a local memory like CPUs)
- A local memory caching implementation, theorically more optimized (target: older GPUs without hardware caching)
- A texture implementation, where the lattice and labels matrices data are stored inside OpenCL images

# Benchmarks

*Note: LWS indicates the Local Work Size. All values have to be considered to the power of two.*

For each device, I benchmarked two images (shown in the [Examples](#examples) section): *grass* and *toronto*.

## NVIDIA GTX 960 4GB

### Grass

Interestingly enough, the **global memory** implementation is slightly but noticeably faster compared to the biggest LWS possible for this GPU.

This is probably due to the fact that modern (Maxwell and later) GPUs have a built in hardware caching system that appears to be faster than the one implemented in the program.

The **texture** implementation doesn't seem to be particularly fast.

<canvas id="benchmark-grass-gtx-960"></canvas>

| Automaton implementation | Execution Time (ms) |
| --- | --- |
| Texture memory                 | 314.70 |
| Local memory caching (LWS: 2)  | 442.45 |
| Local memory caching (LWS: 4)  | 134.47 |
| Local memory caching (LWS: 8)  | 104.27 |
| Local memory caching (LWS: 16) | 97.286 |
| Local memory caching (LWS: 32) | 94.387 |
| Global memory                  | 85.289 |

### Toronto

Weirdly, while tests with other images (of which *grass* is a clear example) show that the **global memory** implementation tends to be the fastest, in this case all the **local memory** implementations are faster than the global memory one.

<canvas id="benchmark-toronto-gtx-960"></canvas>

| Automaton implementation | Execution Time (ms) |
| --- | --- |
| Texture memory                 | 2464.6 |
| Local memory caching (LWS: 2)  | 401.87 |
| Local memory caching (LWS: 4)  | 141.03 |
| Local memory caching (LWS: 8)  | 92.541 |
| Local memory caching (LWS: 16) | 81.911 |
| Local memory caching (LWS: 32) | 81.454 |
| Global memory                  | 1688.5 |

## NVIDIA GTX 760 2GB

### Grass

As with the [GTX 960](#nvidia-gtx-960-4gb), this card also seems to be working best with the **global memory** implementation, despite the fact that it shouldn't have any hardware caching mechanism.

<canvas id="benchmark-grass-gtx-760"></canvas>

| Automaton implementation | Execution Time (ms) |
| --- | --- |
| Texture memory                 | 292.43 |
| Local memory caching (LWS: 2)  | 1513.0 |
| Local memory caching (LWS: 4)  | 464.19 |
| Local memory caching (LWS: 8)  | 161.69 |
| Local memory caching (LWS: 16) | 107.81 |
| Local memory caching (LWS: 32) | 94.520 |
| Global memory                  | 74.223 |

### Toronto

The *toronto* test shows similar results for this card, too. The only difference worth noting is that the **texture** implementation is slightly faster than the **global memory** one.

<canvas id="benchmark-toronto-gtx-760"></canvas>

| Automaton implementation | Execution Time (ms) |
| --- | --- |
| Texture memory                 | 3606.2 |
| Local memory caching (LWS: 2)  | 1334.4 |
| Local memory caching (LWS: 4)  | 416.10 |
| Local memory caching (LWS: 8)  | 151.13 |
| Local memory caching (LWS: 16) | 102.46 |
| Local memory caching (LWS: 32) | 94.520 |
| Global memory                  | 3766.9 |


## Device comparison graph

### Grass

<canvas id="benchmark-all-grass"></canvas>

### Toronto

<canvas id="benchmark-all-toronto"></canvas>

# Examples

| Original | Watershed |
| --- | --- |
| ![Grass](./img/grass.png) | ![Grass watershed](./img/grasswatershed.png) |
| ![Toronto](./img/toronto.png) | ![Toronto watershed](./img/torontowatershed.png) |
| ![Lenna](./img/lenna.png) | ![Lenna watershed](./img/lennawatershed.png) |
| ![Bunny](./img/bbb.png) | ![Bunny watershed](./img/bbbwatershed.png) |
| ![Parrot feathers](./img/parrotfeathers.png) | ![Parrot feathers](./img/parrotfeatherswatershed.png) |

---

*Powered by Markdown using [Marked](https://marked.js.org/). Marked is licensed under [MIT](./marked_LICENSE.md.txt).*

*Charts powered by [Chart.js](https://www.chartjs.org/). Chart.js is licensed under [MIT](./Chartjs_LICENSE.txt).*

        </div>
        <script>
document.getElementById('markdownContent').innerHTML = marked(
    document.getElementById('markdownContent').innerHTML,
    {"sanitize": false}
);

var maincolor = "rgba(75, 192, 192, 0.8)";
var bordermaincolor = "rgba(75, 100, 75, 1)";
var benchlabels = [
    "Texture memory",
    "Local memory caching (LWS: 2)",
    "Local memory caching (LWS: 4)",
    "Local memory caching (LWS: 8)",
    "Local memory caching (LWS: 16)",
    "Local memory caching (LWS: 32)",
    "Global memory"
];
var exectimelabel = "Execution time (ms)";

var multicolor = [
    "rgba(129, 243, 232, 0.8)",
    "rgba(243, 129, 198, 0.8)",
    "rgba(243, 175, 129, 0.8)"
];

var multicolorborder = [
    "rgba(44, 155, 144, 1)",
    "rgba(155, 44, 111, 1)",
    "rgba(155, 88, 44, 1)"
];

var numdevices = 2;

var bench_data = [
    [
        {
            'device': 'NVIDIA GTX 960',
            'bench': 'grass',
            'canvas': 'benchmark-grass-gtx-960',
            'data': [
                314.7,
                442.45,
                134.47,
                104.27,
                97.286,
                94.387,
                85.289
            ]
        },
        {
            'device': 'NVIDIA GTX 760',
            'bench': 'grass',
            'canvas': 'benchmark-grass-gtx-760',
            'data': [
                292.43,
                1513.0,
                464.19,
                161.69,
                107.81,
                94.520,
                74.223
            ]
        }
    ],
    [
        {
            'device': 'NVIDIA GTX 960',
            'bench': 'toronto',
            'canvas': 'benchmark-toronto-gtx-960',
            'data': [
                2464.6,
                401.87,
                141.03,
                92.541,
                81.911,
                81.454,
                1688.5
            ]
        },
        {
            'device': 'NVIDIA GTX 760',
            'bench': 'toronto',
            'canvas': 'benchmark-toronto-gtx-760',
            'data': [
                3606.2,
                1334.4,
                416.10,
                151.13,
                102.46,
                94.520,
                3766.9
            ]
        }
    ]
];

var canvas_data_dict = bench_data[0].concat(bench_data[1]);

canvas_data_dict.map(i => {
    new Chart(document.getElementById(i.canvas).getContext('2d'), {
    	"type": "horizontalBar",
    	"data": {
    		"labels": benchlabels,
    		"datasets": [{
    			"label": exectimelabel,
    			"data": i.data,
    			"backgroundColor": maincolor
    		}]
    	}
    });
});

bench_data.map(group => {
    new Chart(document.getElementById(`benchmark-all-${group[0].bench}`).getContext('2d'), {
        "type": "horizontalBar",
        "data": {
            "labels": benchlabels,
            "datasets": group.map((i, index) => {
                console.log(i);
                return {
                    "label": i.device,
                    "data": i.data,
                    "backgroundColor": multicolor[index%numdevices]
                };
            })
        }
    });
});

        </script>
    </body>
</html>
